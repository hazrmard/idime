{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MQMpU8-sF8v"
      },
      "source": [
        "# Risk & reliability pipeline\n",
        "\n",
        "This notebook encapsulates an end-to-end pipeline for the iDIME project using [toy data(1)](https://people.rit.edu/fa3019/MaintNet/data_aviation.html).\n",
        "\n",
        "The data comprises of two types of documents: `inspection` and `maintenance`. Each document is a text description of the fault and maintenance action done for that fault.\n",
        "\n",
        "The pipeline has the following steps:\n",
        "\n",
        "1. Extracting the maintenance data into a pandas dataframe with two columns. Each column represents `inspection` or `maintenance` actions.\n",
        "2. Converting the text data into vector embeddings for each column using the `gensim` library.\n",
        "3. Using manifold learning to reduce the dimensionality of the vector embeddings for each column.\n",
        "4. Using clustering to identify common modes in the data columns.\n",
        "5. Discretizing dataset. Representing each row of each column by the cluster it belongs to.\n",
        "6. Learning a Bayes net from the discretized model (3).\n",
        "\n",
        "![](https://imgur.com/EOjDofq.png)\n",
        "\n",
        "Citations:\n",
        "\n",
        "1. Akhbardeh, Farhad, Travis Desell, and Marcos Zampieri. \"Maintnet: A collaborative open-source library for predictive maintenance language resources.\" arXiv preprint arXiv:2005.12443 (2020).\n",
        "2. Řehůřek, Radim, and Petr Sojka. \"Gensim—statistical semantics in python.\" Retrieved from genism. org (2011).\n",
        "3. Taskesen, E. (2020). Learning Bayesian Networks with the bnlearn Python Package. (Version 0.3.22) [Computer software]. https://erdogant.github.io/bnlearn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ThWiGxe9Srr"
      },
      "outputs": [],
      "source": [
        "# see here for sentence transfrmers : https://www.sbert.net/\n",
        "# https://huggingface.co/sentence-transformers/all-mpnet-base-v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl5Tvmf-nzqD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gensim\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#TODO: try different manifold leaning algorithms:\n",
        "from sklearn.manifold import Isomap\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "#TODO: try out different clustering algorithms:\n",
        "from sklearn.cluster import HDBSCAN, DBSCAN\n",
        "from sklearn.mixture import BayesianGaussianMixture\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# import plotly\n",
        "# import plotly.express as px\n",
        "# import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYd2Tx1Av6w2"
      },
      "source": [
        "## Parsing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "YTrBHW342Wa0",
        "outputId": "507ee7c7-33ad-4bc8-b6a7-fe2206d31686"
      },
      "outputs": [],
      "source": [
        "# Reading the toy dataset, and showing a sample of rows\n",
        "DOWNLOAD = True\n",
        "PROD = False\n",
        "if DOWNLOAD:\n",
        "    df = pd.read_csv('https://people.rit.edu/fa3019/technical/data/maintnet_aviation_dataset_deidentified.csv', index_col='IDENT')\n",
        "    n = len(df)\n",
        "    df['Inspection'] = df.Inspection\n",
        "    df['Maintenance'] = df.Maintenance\n",
        "    df['TimeCost'] = np.random.rand(n) * 10\n",
        "    del df['PROBLEM']\n",
        "    del df['ACTION']\n",
        "    df.to_csv('./data/maintnet.csv')\n",
        "elif not PROD:\n",
        "    df = pd.read_csv('./data/maintnet.csv')\n",
        "elif PROD:\n",
        "    df = pd.read_csv('./data/acn.csv')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-Q0aV-Q3EXR"
      },
      "outputs": [],
      "source": [
        "# Converting the dataframe in to 2 corpora of documents for gensim.\n",
        "# gensim will independently process each class of documents (inspection, maintenance)\n",
        "# for later analysis.\n",
        "def read_documents(s: pd.Series, tokens_only=False):\n",
        "        for i, line in enumerate(s):\n",
        "            tokens = gensim.utils.simple_preprocess(line.lower())\n",
        "            if tokens_only:\n",
        "                yield tokens\n",
        "            else:\n",
        "                # For training data, add tags\n",
        "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
        "\n",
        "documents_insp = list(read_documents(df.Inspection))\n",
        "documents_main = list(read_documents(df.Maintenance))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_twfaod2v-Wk"
      },
      "source": [
        "## Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8LeU8Gl4kGg"
      },
      "outputs": [],
      "source": [
        "# Using Doc2Vec, represent each document (each row in a column) as a vector\n",
        "# Two models are learned, each for inspection and maintenance documents\n",
        "VECTOR_SIZE = 32\n",
        "def make_model(corpus, vector_size=VECTOR_SIZE):\n",
        "    model = gensim.models.doc2vec.Doc2Vec(vector_size=vector_size, min_count=2, epochs=40)\n",
        "    model.build_vocab(corpus)\n",
        "    model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "    return model\n",
        "\n",
        "model_insp = make_model(documents_insp)\n",
        "model_insp.save('./bin/doc2vec_insp')\n",
        "model_main = make_model(documents_main)\n",
        "model_main.save('./bin/doc2vec_main')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miZXtSXb5faV"
      },
      "outputs": [],
      "source": [
        "# Query the model for similar documents. Once the index of a similar inspection\n",
        "# document is known, the corresponding maintenance action can be pulled up:\n",
        "inspection_report = 'engine not starting'\n",
        "vector = model_insp.infer_vector(\n",
        "    gensim.utils.simple_preprocess(inspection_report.lower())\n",
        "    )\n",
        "sims = model_insp.dv.most_similar([vector], topn=10)\n",
        "print('Most similar records:\\n')\n",
        "for idx, score in sims:\n",
        "    print('INSP:', df.iloc[idx].Inspection)\n",
        "    print('MAIN:', df.iloc[idx].Maintenance)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LSI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gensim.models import LsiModel\n",
        "from gensim.models import TfidfModel\n",
        "from gensim import corpora\n",
        "\n",
        "texts = [d.words for d in documents_insp]\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus_insp = [dictionary.doc2bow(t) for t in texts]\n",
        "tfidf = TfidfModel(corpus=corpus_insp)\n",
        "corpus_tfidf = tfidf[corpus_insp]\n",
        "\n",
        "lsi = LsiModel(corpus=corpus_insp, id2word=dictionary)\n",
        "corpus_lsi = lsi[corpus_tfidf]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus_lsi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St6dkIdDwHJC"
      },
      "source": [
        "## Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ai7Hk6HS7_Nd"
      },
      "outputs": [],
      "source": [
        "# Use a manifold learning algorithm to reduce dimensionality for each document class\n",
        "DO_MANIFOLD = True\n",
        "if VECTOR_SIZE > 3 and DO_MANIFOLD:\n",
        "    embedding = Isomap(n_neighbors=5, n_components=3, metric='cosine')\n",
        "    x_insp = embedding.fit_transform(model_insp.dv.vectors)\n",
        "    x_main = embedding.fit_transform(model_main.dv.vectors)\n",
        "    predict_embedding = embedding.transform\n",
        "else:\n",
        "    x_insp = model_insp.dv.vectors.copy()\n",
        "    x_main = model_main.dv.vectors.copy()\n",
        "    predict_embedding = lambda x: x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igSFiR6RT5FP"
      },
      "outputs": [],
      "source": [
        "# Cluster the embeddings\n",
        "pipe_insp = Pipeline([\n",
        "    ('normalization', Normalizer()),\n",
        "    ('clustering', HDBSCAN(min_cluster_size=100, metric='euclidean'))\n",
        "    # ('clustering', DBSCAN(n_components=20))\n",
        "])\n",
        "y_insp = pipe_insp.fit_predict(x_insp)\n",
        "\n",
        "pipe_main = Pipeline([\n",
        "    ('normalization', Normalizer()),\n",
        "    ('clustering', HDBSCAN(min_cluster_size=50, metric='euclidean'))\n",
        "    # ('clustering', DBSCAN(n_components=20))\n",
        "])\n",
        "y_main = pipe_main.fit_predict(x_main)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkABKEHc8Q2W"
      },
      "outputs": [],
      "source": [
        "from plotly.subplots import make_subplots\n",
        "fig = make_subplots(rows=1, cols=2, specs=[[dict(type='scene'), dict(type='scene')]])\n",
        "scatter_kwargs = dict()\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter3d(x=x_insp[:,0], y=x_insp[:,1], z=x_insp[:,2], text=df.Inspection,\n",
        "                 name='Inspection',\n",
        "                 mode='markers',\n",
        "                 marker=dict(\n",
        "                    size=2,\n",
        "                    color=y_insp,\n",
        "                    colorscale='Viridis',\n",
        "                    opacity=0.8\n",
        "                )),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter3d(x=x_insp[:,0], y=x_insp[:,1], z=x_insp[:,2], text=df.Maintenance,\n",
        "                 name='Maintenance',\n",
        "                 mode='markers',\n",
        "                 marker=dict(\n",
        "                    size=2,\n",
        "                    color=y_main,\n",
        "                    colorscale='Viridis',\n",
        "                    opacity=0.8\n",
        "                )),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "fig.update_layout(height=600, width=1200, title_text=\"\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ag9PX6Qwu8s"
      },
      "source": [
        "## Bayesian learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "_ZryYyaRKgse",
        "outputId": "b0029e29-7084-4f52-a137-be76f1ad5b83"
      },
      "outputs": [],
      "source": [
        "# Discretize the data using cluster labels\n",
        "ddf = pd.DataFrame({'insp': y_insp, 'main': y_main}, index=df.index)\n",
        "ddf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-gH97H_tW0JA",
        "outputId": "a77663a2-70f5-43aa-e2c8-24a1f8c71db8"
      },
      "outputs": [],
      "source": [
        "# Learn a bayesian model, assuming a node structure\n",
        "import bnlearn as bn\n",
        "\n",
        "edges = [list(ddf.columns),]\n",
        "dag = bn.make_DAG(edges)\n",
        "# parameter learning\n",
        "model = bn.parameter_learning.fit(dag, ddf)\n",
        "model = bn.independence_test(model, ddf, prune=False)\n",
        "bn.plot(model, interactive=False, params_static = {'width':4, 'height':4,})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7hvLtjiIbfZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "kn = KNeighborsClassifier()\n",
        "kn.fit(x_insp, y_insp)\n",
        "\n",
        "vectorize = lambda x: model_insp.infer_vector(\n",
        "    gensim.utils.simple_preprocess(x.lower())\n",
        "    )\n",
        "\n",
        "def predict_insp_cluster(text, vectorize=vectorize, embed=predict_embedding, cluster=kn.predict):\n",
        "    v = vectorize(text)\n",
        "    e = embed([v])\n",
        "    c = cluster(e)\n",
        "    return c[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVTZBIQ7NEMs",
        "outputId": "42e94100-3ad1-404f-d2a3-a8ddbb5179c0"
      },
      "outputs": [],
      "source": [
        "predict_insp_cluster('gasket is leaking')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92DHj2pfOZE8"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "m = model['model']\n",
        "t=m.cpds[1]\n",
        "t.values\n",
        "fig = go.Figure(data =\n",
        "    go.Contour(\n",
        "        z=t.values,\n",
        "        x=sorted(list(set(ddf.insp))),\n",
        "        y=sorted(list(set(ddf.main)))\n",
        "    ))\n",
        "fig.update_layout(width=500, height=500, xaxis_title='Insp', yaxis_title='Main', title='Conditional Probability distribution P(main | insp)')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_tDrXnGXefz"
      },
      "outputs": [],
      "source": [
        "# Given some evidence (say, about inspection 'insp'), make predictions about\n",
        "# maintenance 'main'\n",
        "# Inference\n",
        "evidence = {\n",
        "    'insp': predict_insp_cluster('gasket is leaking'),\n",
        "    }\n",
        "res=bn.inference.fit(model, variables=['main',],\n",
        "                     evidence=evidence, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43hCh9SFT3qI"
      },
      "outputs": [],
      "source": [
        "examples = res.sample(10).values.flatten()\n",
        "fig = px.histogram(examples)\n",
        "fig.update_layout(width=600, height=300, xaxis_title='Maintainance action cluster')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KphMckyv4hNo",
        "outputId": "118834aa-338e-4f39-8753-f5148972113b"
      },
      "outputs": [],
      "source": [
        "labels = pipe_insp.named_steps['clustering'].labels_\n",
        "unique_labels, counts = np.unique(examples, return_counts=True)\n",
        "for l, c in zip(unique_labels, counts):\n",
        "    idx = np.arange(len(examples))[examples==l]\n",
        "    idx = np.random.choice(idx, size=c)\n",
        "    print('\\nCluster %d, %d samples\\n================' % (l,c))\n",
        "    for i in idx:\n",
        "        print(df.Maintenance.iloc[i])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "oNJEl7Mp3FS6"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
